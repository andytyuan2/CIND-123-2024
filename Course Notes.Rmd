---
title: "CIND 123 Course Notes"
author: "Andy Yuan"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

# Week 1: Jan 11 - Jan 18, 2024
## Module 1: Introduction to Statistics and the R environment

### Introduction to Statistics
Statistics is the study of how best to collect, analyze, and draw conclusions from data.

**There are three concepts that we will want to keep in mind:**

1. Statistics is an applied field with a wide range of practical applications
2. Statistics will help us learn from real and interesting data
3. Statistics help advance our understanding of the world and ourselves

One basic idea in stats is the use of samples: Samples are pulled from a population, where a population is the entire set.

**This branches off into techniques to present the data:**

- Descriptive statistics:
  - Makes a conclusion based off of the entire population
  - Describes sets of measurements we can take on the population
  
- Inferential statistics:
  - Uses a sample to generalize about the population
  - Important that the sample can represent the population
  
### Variables and Data
Variables are a characteristic that changes over time, like hair or jewelry that varies from person to person. An experimental unit is a set where the variable can be measured.

**Data is individual pieces of information, so data is a set of qualitative and quantitative variables.** 

- Univariate data: when a single variable is measured on a single experimental unit
- Bivariate data: two variables are measured on a single experimental unit
- Multivariate data: more than two variables are measured on a single experimental unit

Eg, 50 students (experimental unit) who get their test scores (variable) measured

**Data is further divided into two groups: qualitative and quantitative**

- Quantitative data: Can be measured and assigned a number
  - How long someone's hair is
- Qualitative data: Can be observed but not measured
  - What colour someone's hair is
  
### Introduction to R
R is a software for statistical computing and graphics. It can do calculations, manipulate data, program, and create graphics. There is a slew of statistical tools available on R as well as web packages for easy use. 


## Swirl Lessons 1-3
R does not use the equal symbol to assign variables, but instead uses <-. If thought of as an arrow, then the right side value is being assigned to the left side variable. 

Let's look at an example:
```{r}
x <- 5+7
y <- x-3
y
```

A vector in R is a small collection of numbers, and a data structure is an object that contains data.In R, we use the concatenate function to combine numbers into vectors.This function goes like "c(x, y, z...)"

We can try assigning a few numbers to a vector here:
```{r}
z <- c(1.1, 9, 3.14)
z
```

You can even assign a vector inside of a vector as so:
```{r}
c(z, 4, z)
```

Just like a vector in linear algebra, multiplying a vector in R will give you each item multiplied by the number. You are also able to add to it.

```{r}
z + 100
```

However, you are also able to use the sqrt function with vectors, which will give you the square root of each of the numbers within the vector.You are also able to divide a vector by a vector, which will give you the first element of the first vector divided by the first element of the second vector, then the second element of the first vector divided by the second element of the second vector, and so on.

If one vector is shorter than another, then it recycles itself until it fits with the longer vector. 

**If you ever get confused on what a function does, then you can use the '?' symbol with the function following, though this will open up the page in your web browser, which may not be the desired action, so I will not include it here.**

Sequences of numbers in R are similar to Python, where you use the colon between the numbers to signify this number to another. The default is increments of 1 that can go backwards, through decimals, or anything in between.

```{r}
1.1:-10
```

You can also establish more control over the sequencing by using the seq() function. 

```{r}
seq(1, 10, by=0.5)
seq(5,10, length=30)
```

The second sequence automatically sets an interval so that we can get 30 items between 5 and 10 inclusive.

If you wanted a sequence the same length as another, you can use the **seq_along()** function or the **seq(along.with = desired sequence)**.

R can also replicate a sequence of numbers using the **rep()** function:
```{r}
rep(0, times = 10)
rep(c(1, 2, 3), times = 40)
rep(seq(5,10, by=0.7), times = 2)
rep(c(0,1,2), each = 10)
```

## Readings for Week 1
### Intro stats with R, chapter 1.1
**1.1.5 Graphics**

(plot) is the function for plotting out two sets of data
- Can add other variables such as "pch", will will change the plotting character


## Lab for Week 1
Download the bp.obese package in ISwR dataset:

Install the ISwR package by using:

```{r}
library(ISwR)
```


After that, load the package "bp.obese" using the data() function and then preview using the head() function:
```{r}
data(bp.obese)
head(bp.obese)
```

To summarize the structure of the dataset, use summary() function,
To get an overview of the dataset, use the str() function

```{r}
summary(bp.obese)
str(bp.obese)
```

Use the help() function to check the names and descriptions of the other example datasets in the ISwR package.

## Removing variable assignments
We can remove the assignments of variables from previous chunks of R code using the rm() function
```{r}
rm(list = ls())
```
The above code removes the assignments of code that we previously used and allows us to start fresh for the next lesson.

# Week 2: Jan 18 - Jan 25, 2024
## Module 2: Assignments and Vectors in R

### Assignments and vectors in R
When you are assigning variables, you can actually have the assignment the other way, but will have to change the direction of the arrow. The assignment will always point from assigned value to variable.

Similarly, you can create assignments of vectors in R, where you are also able to find things like length and and elements. Elements in R start from 1, not 0 like in Python

```{r}
x <- c(10, 20, 30, 40)
length(x)
x[2]
```
R has a handy function where you are also able to take out an element of a vector by assigning a new variable the old vector with a minus sign saying you want to get rid of the numbered element:
```{r}
y <- x[-3]
y
```

Vectors cannot be mixed, as in they cannot be both numeric and verbal:
```{r}
z <- c(2, "word", 3)
z
rm(list = ls())
```

### Data Types in R

You can test for data types in R using the **class()** function or **is."data type"()** function. Let's go through the types of data in R.

**1. Numeric Data**

  - Any numeric value is assumed to be a numeric data type as soon as it is assigned. 
  - Similar to the float number type in Python
  - Integers must first be assigned as integers to be used as one
```{r}
z <- 10
x <- as.integer(10)
class(z)
class(x)
```

**2. Character Data**

  - Any value that is not a number
  - Should use quotation marks to denote
  - R is case sensitive
```{r}
character <- "data"
class(character)
```

**The factor() command**
- Used to examine unique values of a factor variable
```{r}
y <- factor("data")
y
```

**3. Date Data**

  - as.date() will store your date as a date data type
  - should use quotation marks again here
  - You can change the order of the date by specifying as you are assigning the date
  - R will always go Year, Month, Day
```{r}
date1 <- as.Date("2012/05/03", "%Y/%d/%m")
date1
```

**4. Logical Data Type**

  - Since 1 is true and 0 is false, then any operations done to them will result in either 1 times X or 0 times X
  - You are also able to assign variables as true or false, which will give it a logical class
  - like in Python, "==" is equal to, while "!=" is not equal to
  
```{r}
TRUE * 5
FALSE * 5
rm(list = ls())
```

### Matrices in R
We use matrices in R to perform operations similar to uses in linear algebra. As always, the matrix is ROW x COLUMN when saying it. We make sure that when creating a matrix, then we are able to first define the numbers within it, then the dimensions that they fit in. 

All elements of a matrix must be the same type, while a data frame can have different data types in different columns

```{r}
x <- 1:12
dim(x) <- c(3, 4)
# dim(x) is not a variable, but instead defining what dimensions x has
x
```
This operation will give a matrix that has the numbers from 1 to 12, with 3 rows and 4 columns. A couple things to note are that R starts in the top left, will progress its way down the first column, then start again at the top of the next column until it finishes its course. By default, R writes matrices column by column.

To call a row of x, you just need the row number and a blank for the column number. This same logic is applied to the columns. Of course, if you do specify, then you can pull a specific cell in the matrix
```{r}
x[1,]
x[,3]
```

The fascinating and useful tool that R has is that it can also alter how it writes matrices. Particularly, it can write them row by row if you use the **byrow** command. It works by using either T(True) or F(False)

Furthermore, R can also fill in the blanks for you when you are making matrices. If you specify the number of rows you want, then it will be able to fill in the number of columns; it can also do this the other way around.
```{r}
matrix(c(1, 6, 2, 5, 3, 4), nrow = 3, byrow = T)
matrix(1:12, ncol = 6)
matrix(5:14, ncol = 5, byrow = T)
```

There are a few commands in R that are very useful for building out matrices.

  - The **cbind** command will bind vectors together column-wise.
  - The **rbind** command will bind vectors together row-wise.
  
```{r}
cbind(A=1:4,B=5:8,C=9:12)
rbind(A=1:4, B=5:8, C=9:12)
```

Another useful function of matrices is being able to extract out a specific row or column, just like how we did for vectors.
```{r}
m <- matrix(1:12, nrow = 4)
m
m[1,3] # this specifies an element in the matrix
m[-2,] # this will take out the second row
rm(list = ls())
```

## Swirl Lessons 4-8
### Lesson 4: Vectors
Two vector types in R for storing data:

- Atomic vectors: contains only one data type
- Lists: Can contain multiple data types


Vector types for storing specific data:

- Logical vectors: Contain values TRUE, FALSE, and NA
  - TRUE = 1, FALSE = 0, NA is 'Not Available'
  - '|' is the symbol for 'or'
  - '&' is the symbol for 'and'
  
- Character Vectors: contains strings that are set by double quotations
  - We can combine the words in a character vector using the paste() function, and make sure to include the collapse = " " after the vector so it gets inserted between the vector elements being combined
  - We can also just combine two strings using the sep = " " command to ensure there is a space between the two
  - If we combine two vectors with no spaces in between using the paste function, then they'll cycle within each other

```{r}
paste(c(1:3), c("X", "Y", "Z"), sep = "")
paste(LETTERS, 1:4, sep = "-")
```

### Lesson 5: Missing Values
- Missing values are NA, and should be studied to find the underlying reason they exist in our data
```{r}
x <- c(44, NA, 5, NA)
```
- We can draw from the normal distribution by using the **rnorm()** function, which you specify how many draws
  - Randomize the draws by using the **sample()** function, which takes a random sample of the vectors you specify, and how large the sample should be
  
- Another type of missing value is "NaN", which stands for "not a number"
  - For example, things like 0/0 is NaN, or Inf-Inf
  
### Lesson 6: Subsetting vectors
- Subsetting vectors is indexing what you want out of the vector
  - They come in 4 types:
    - Logical Vectors
    - Vectors of positive integers
    - vectors of negative integers
    - vectors of character strings
- You can index by stating a condition: x[x > 0] will give you all elements greater than 0 in the x vector
  - Conditions can be combined using the and (&) or OR commands
- We can use "!" with is.na() to get the non NA elements of a vector
  - We have to get rid of the NA by assigning to another vector first. If not, then since NA > 0 or NA < 0 will be true, then you will have NA in your original vector values

- We can also subset all BUT some elements by using the negative notation
  - x[c(-2, -10)] will give you all BUT number 2 and 10
  
- Another thing we can do is name vectors
  - Normally, this is done through writing the name = the value
  - We can also write the names after the fact by using the names() function, then assigning the names using a character vector
```{r}
vector_name <- c(11, 2, NA)
names(vector_name) <- c("wow", "NOOO", "borf")
vector_name
rm(list = ls())
```

### Lesson 7: matrices and data frames
- matrices are only one type of data, data frames can be more than one type of data
- If you want to name the columns of a matrix, you need to make it a data frame with the **data.frame()** function

To make column names, you use the **colnames()** function, which takes the data frame and you can assign it to the column names vector created

### Lesson 8: logic in R
<, >, <=, >=, ==, !=
- There are two AND operators in R, the main being '&' and the other being '&&'
  - '&' can evaluate across a vector, while '&&' only evaluates the first member of a vector
```{r}
TRUE & c(TRUE, FALSE, FALSE)
# TRUE && c(TRUE, FALSE, FALSE)
```
  - Similarly, the OR operator, '|' can evaluate across a vector, while the double OR, '||', evaluates only the first element in the vector
  
- All **AND** operators are evaluated before any **OR** operators, while any value operators happen before any AND or OR operators

Some ways of evaluating the logical of the statements you write are the **isTRUE()** function and the **isFALSE()** function. Similarly, you can evaluate the sameness of vectors or functions using the **identical()** function.
  - The **xor()** function evaluates an exclusive OR. If one argument is TRUE and the other FALSE, then the whole function will return TRUE. Even when both are TRUE, then the function will return FALSE
  - The **which()** function evaluates the indices of a logical vector to give you the ones that are TRUE
  - The **any()** function will give you TRUE if one or more elements is TRUE
  - The **all()** function will give you TRUE only if all elements are TRUE

## Module 2 readings: 1.2 - R language Essentials

1. Expressions and Objects
  - Expressions always return a value, sometimes a side effect like a graph or writing to a file
  - Expressions work on objects in R; Objects are anything that can be assigned to a variable in R

2. Functions and arguments  
  - Things like functions have *actual arguments* and *formal arguments*
    - **Actual arguments** will only apply to the current call in use
      - These can be specified but are also typically assumed in most R functions
    - **Formal arguments** will be used in connection to actual arguments in the call
```{r}
height <- c(1:4)
weight <- c(4:1)
plot(weight, height, pch = 2) #Assumes weight is x axis and height is y axis, this is called positional matching. pch is a named formal argument that can specify what it does, this is called keyword matching. 
```

  - You can check what a function has for arguments by using the args() command.
```{r}
args(plot.default)
```


3. Vectors
  - Character vectors
  - Logical vectors

4. Quoting and escape sequences 
 - When you write a character vector, you use the quotation marks to differentiate the string to R
    - To be able to print the strings out without the quotation marks, you can use the **cat()** function
  
```{r}
cat(c("wow", "he", "michael"))
```
There is no way to tell this vector from a single string of "wow he michael"
 
 - Escape sequences are useful because it tells R that you would like to start a new line
    - Example include "\n", inserting quotations in a string like \"
```{r}
cat("What is \"R\"?\n")
```

5. Missing values
  - Vectors can carry an N/A value to specify a missing value
  
6. Functions carry vectors
  - **c()** function carries a vector by concatenating them; ie, joining them end to end
      - Elements of the concatenate vector must be the same type of data, and will be converted where R sees fit
      - You can also assign names to the elements, which modifies how they are printed
```{r}
colours <- c(red="aka", blue="ao", green="midori")
names(colours)
```

  - Another type of concatenate function is the **seq()** function, which makes a sequence of numbers from one specified one to another. You can also specify how much you want to jump between the numbers in the sequence. This is particularly useful for larger sets of numbers that would take too long to use the c() function
  
```{r}
seq(10, 20, 2) # sequence from 10 to 20, taking steps of size 2
```

  - The third type of vector creating function is the **rep()** function. It is used to generate repeated values based the second argument, which can be either a vector or single number
  
```{r}
vector <- c(7, 9 ,13)
rep(vector, 3) # a single number will repeat the vector in its entirety x times
rep(vector, 2:4) # a vector will specify how many times each element in the vector should be repeated. In this case, the first is repeated twice, the second three times, and the third four times
```
This function is particularly useful when you need a data set that repeats the same value more than once
```{r}
# a set of 10 men and 15 women will be as follows
rep(c("men", "women"), c(10, 15))
```


7. Matrices and arrays
  - Useful functions:
      - **rownames()** - Gives the row names
      - **colnames()** - Gives the column names
      - **t()** - Transposes the matrix
      
8. Factors
  - Factors are categorical variables usually assigned a numeric code. They assign meaningful names to categories.
  - Each factor has levels which are specified to represent a certain number
  
```{r}
pain <- c(0, 3, 2, 3, 1) # data of pain levels of patients
fpain <- factor(pain, levels = 0:3) # setting the pain levels as a categorical variable and assigning level numbers
levels(fpain) <- c("none", "mild", "moderate", "severe") # assigning meaning to the level numbers
fpain # shows the levels in terms of the assigned meanings
as.numeric(fpain) # changes the levels to start from 1
```


9. Lists
  - The **list()** function is used to combine a collection of objects into one. Each component can be named as well, so it will be neater to show more data sets at once.
  
```{r}
intake.pre <- c(5260,5470,5640,6180,6390,
                6515,6805,7515,7515,8230,8770)
intake.post <- c(3910,4220,3885,5160,5645,4680,5265,5975,6790,6900,7335)

mylist <- list(before=intake.pre, after=intake.post)
mylist # shows both parts of the list
mylist$before # will show the specified portion, using the $ sign as the defining character for which part
```


10. Data frames
   - A list of vectors and other factors of the same length, similar to a spreadsheet and its multiple columns
   - Similar to lists, the specific component may be accessed using the $ sign
```{r}
d <- data.frame(intake.pre, intake.post) # this data is paired, so the rows are the same person
d
```

11. Indexing
  - You can access a specific part of a vector like in python using the square brackets
  - You can also change that specific element by assigning it a new value
  - You can specify multiple instances using a vector instead of a single number, but NOT the set of numbers without the c() function
  
```{r}
wow <- c(12:1)
wow[c(3, 5, 7)]
```

12. Conditional Selection
  - You would need to extract based off some criteria most of the time
  - The criteria needs to be the same length as the desired set you are taking from, kind of like vlookups with Excel
```{r}
intake.post[intake.pre > 7000]
```

  - Some logical operators are:
    - "&" for and
    - "|" for or
    - "!" for not
  - Useful functions include:
    - **is.na()** will show elements are recorded as missing or N/A
    
13. Indexing of data frames
  - uses the row by column format like matrices, so a specific element would look like **data.frame[1, 2]**, while the row would be **data.frame[1, ]**
  - Can also use conditional selection to extract
```{r}
d[d$intake.pre > 7000, ] # shows all rows where intake.pre is higher than 7000
```

14. Grouped data and data frames
  - For some datasets, you are able to categorize them, so it is easier to store them in sets rather than in the same place
  
```{r}
expend <- c(1, 4, 2, 5, 1, 9, 3, 4)
stature <- c("obese", "lean", "obese", "lean", "obese", "lean", "obese", "lean")
energy <- data.frame(expend, stature)
energy

exp.lean <- energy$expend[energy$stature == "lean"] # separates expenditure into lean body type
exp.obese <- energy$expend[energy$stature == "obese"] # separates expenditure into obese body type
```

You can also split a data set according to some grouping
```{r}
one <- split(energy$expend, energy$stature) # splits expend by the grouping in stature
```

15. Implicit loops
  - Used to apply a function to each element of a vector
  - Useful functions in this space:
      - **lapply()** - always returns a list 
      - **sapply()** - always tries to simplify the result to a vector or matrix if possible
      - **tapply()** - creates a table using the sets you specify, groups by second argument
      
```{r}
lapply(mylist, mean, na.rm=T) # specifies what it wants to apply the function to, specifies the function, na.rm=T is ensuring any N/A values are removed

sapply(mylist, mean, na.rm=T) # does the same as lapply, but will use a vector to show in this case

tapply(energy$expend, energy$stature, median)
```


16. Sorting 
  - Sorting a vector uses the **sort()** function to sort it from smallest to largest
  - ordering a vector according to another uses the **order()** function
  
```{r}
order(intake.post) # Gives numbers 1 to 11 (length of the vector), sorted by the size of the argument
# other variables can be sorted by this same criterion. This is the strength of the order() function
rm(list = ls())
```


## Lab 2
1. Using the c() and sum() functions
```{r}
FireName <- c("Waskesiu CFB", "Birch Bay", "Waskesiu CFB", "Wasstrom's Flats", "Millard", "Rabbit", "Sandy North", "Namekus Lake", "Waskesiu CFB", "Millard", "National", "Wasstrom's Guards", "South End Meadows")

BurnedArea <- c(40, 0.1, NA, 834, 1483, 20228, NA, 1.2, 56, 693, 0.5, 30, 830)

sum(BurnedArea, na.rm = T)/(length(BurnedArea) - sum(is.na(BurnedArea)))
```

2. Using the cbind() function
```{r}
Year <- c(rep(2019, 2), rep(2018, 6), rep(2017, 4), 2016)
Year <- factor(Year, ordered = TRUE) # this makes it an ordinal variable
Year
Fires <- cbind(Year, FireName, BurnedArea)
# the limitation of the cbind() function is that it converts all the variables to the same type

Fires[1,2] # first row, second column
dim(Fires) # 13 rows by 3 columns
nrow(Fires) # number of rows in the data
```


3. Working with Matrices
```{r}
iMatrix <- matrix(c(1,2,3,4,2,1,2,3,0), nrow = 3, byrow=T)
```
  - Use R to compute the following:
    - Transpose of the matrix
```{r}
transpose <- t(iMatrix)
```
    - inverse of the matrix
```{r}
inverse <- solve(iMatrix)
inverse
```
    - multiplication of the matrix by its inverse
```{r}
inverse %*% iMatrix # %*% is the notation for matrix multiplication
rm(list = ls())
```

# Week 3: Jan 25 - Feb 1, 2024
## Module 3: Graphs, lists, arrays, and data frames in R

### Graphs for categorical data
After data has been collected, we typically ask of two things to use as analysis: what values have been measured, and how often has each value been accrued? 

When the data is qualitative or categorical, then the table we can create from the data is a list of categories. The oftenness of the variable can be the frequency, the relative frequency, and the percentage of measurements.
  - Frequency is just the number of times the variable occurs
  - Relative frequency is the number of times the variable occurs in a category
  - Percentage of measurements is the percentage, so the relative frequency * 100
  
Types of charts vary based on how you want to show your data
  - Bar Chart
```{r}
rating <- c("A", "B", "C", "D")
Frequency_of_rating <- c(35, 260, 93, 12)
barplot.default(height = Frequency_of_rating, names.arg = rating)
```

  - Pie Chart, needs to be made into a percentage
```{r}
percentages_pie <- sapply(Frequency_of_rating, function(n) (n/sum(Frequency_of_rating))*360)
pie(percentages_pie, labels = rating)
```

### Graphs for quantitative data
Graphs for quantitative data include line charts, dot plots, stem and leaf plots, and relative frequency histograms.

When a quantitative variable is recorded over time, the most efficient way of displaying the data is with a line chart
```{r}
years <- seq(2006, 2031, by = 5)
Population <- c(1227.3, 1513.1, 1942.1, 2184.7, 2466.6, 2527.6)
plot(years, Population, type = "l")
```


For a dot plot, you want to stack the data points on top of each other on the number line which represents the range of the data
```{r}
data_dot <- c(1,2,3,5,2,1,2,4,5,1,5,2,2,5,6,7,3,3,5,2,3)
stripchart(data_dot, method = "stack", pch = )
```

And finally, for a stem and leaf plot, you want to have the tens column as the stem and the ones column as the leaf. It will represent a frequency distribution.
```{r}
data_stem <- c(11, 12, 13, 14, 20, 30, 32, 34, 33, 21, 17)
stem(data_stem)
```

Lastly, you use a histogram to show frequency.
```{r}
hist(data_dot)
rm(list = ls())
```


### Arrays, lists, and data frames in R
#### Arrays
Arrays are three-dimensional matrices, where the first two dimensions will be rows and columns, while the third dimension tells you the number of matrices attached to the array.

Arrays can have an arbitrary amount of dimensions
```{r}
firstterm <- matrix(c(76, 61, 80, 70, 65, 90), nrow = 3)
secondterm <- matrix(c(86, 71, 90, 83, 65, 90), nrow = 3)
tests <- array(data= c(firstterm, secondterm), dim = c(3,2,2))
tests
```
Arrays have indexing exactly the same as matrices, but you will need to specify from which matrix you want to pull the specified rows and columns from.


#### Lists
Lists are a generalization of arrays, which can contain different data types, and are called using the '$' sign. 
```{r}
x <- list(u=2, v="abc")
x
x$u
```

#### Data frames
data frames are actually lists, but each component of the list is a vector corresponding to a column. They are the best way to store data.

```{r}
data_frames = data.frame(name=c("Ann", "Bo", "Carl", "Dee"), gender=c("F","M","M", "F"), height=c(150, 140, 170, 130), weight = c(140, 160, 140, 160))
data_frames
# The way to subset and call out the data frame is to use the '$' sign to call the specific vector, then subset using the square bracket to get within the vector itself. 
data_frames$gender[3]
# You are also able to get the rows and columns as normal using the square brackets
data_frames[3, 2]

# Also, you can subset the data with some conditions
subset(data_frames, data_frames$gender == "F")
subset(data_frames, height > 140)
rm(list = ls())
```


## Swirl Lesson 15: Base Graphics


# Week 4: Feb 1 - Feb 8, 2024
## Module 4: Measures of univariate, bivariate data; functions of R

### Describing data with numerical measures
Numerical measures can be precise and provide a concrete way to look at a data set.

There are various things that can be considered. 

1. Mean (x bar)
  - sum of the data set / number of items
  - More easily affected by large or small values than the median
$$
E[X] = \sum(X_i) / N
$$
2. Median (x squiggly)
  - Put the data set in order, then find the middle of the data set. If even, then take the average of the two middle values.
3. Mode 
  - The most common number of the data set, there can be more than one mode, so we do not use averages here 
4. Variance
  - Variance is the sum((xi - e(x))^2) / N for population, but n-1 for samples
  - It can also be calculated by expected values:
$$
V[X] = E[X^2] - E[X]^2
$$
5. Standard Deviation 
  - Always positive 
  
### Numerical measures in data part 2

#### Tchebysheff's Theorem
- For a number k that is greater than or equal to 1, at least $$ 1- 1/(k^2) $$ percent of measurements will lie within 'k' standard deviations of the mean. Same concept as the normal distribution percentage ranges for numbers of standard deviations from the mean.

Eg, for a number k = 2, then the percent of measurements that will lie within 2 standard deviations from the mean is 1-1/4 = 75% of measurements.

  - The empirical rule is the same concept, but has exact measurements
    - 68% of measurements within 1 standard deviation
    - 95% within 2 standard deviations
    - 99.7% within 3 standard deviations
    
    
#### The z-score
A way to find how far a data point is from the mean, described in terms of standard deviations
$$ z-score = \frac{x - E[X]}{\sigma} $$
A larger z-score denotes a higher possibility that the data point is an outlier in the data set since it is further away from the mean.

#### Percentiles
Percentile shows the number of measurements above and below a certain data point
  - Q1: first quartile - first 25% 
  - Q2: second quartile, also called the median, 50%
  - Q3: third quartile - first 75%
  - Interquartile: middle 50% of the data set, Q3 - Q1
  
#### Box plots
The parts to a box plot are as follows:
  - The box is made up of Q1 and Q3 as the outer edges, the median in between, then the whiskers extend to 1.5x of the interquartile range from each quartile.
  
### numerical measures for quantitative bivariate data
Bivariate data is for when two variables are measured on a single experimental unit
  - It's easy to make a scatterplot on bivariate data since one can be on the x axis and the other on the y axis
  
  
### Functions in R
- Functions are objects in R, and are assigned to variables the same as other functions
- They have their own class, 'function'

```{r}
f <- function(a) {
  a^2
}
f(2)
```

```{r}
series <- function(x, y) {
  z1 <- 2*x + y
  z2 <- 5*x - y
  z3 <- x + 5*y
  return(c(z1, z2, z3))
}

series(2, 3)
```

#### variance function in R
```{r}
library(ISwR)
attach(thuesen)
var(thuesen$blood.glucose) # variance function in R
sd(thuesen$blood.glucose) # standard deviation function in R
scale(thuesen$blood.glucose, center = TRUE, scale = TRUE) # Z scores of the data, the bit at the end is the mean and the standard deviation
summary(thuesen$blood.glucose) # the six summary numbers (Minimum, Q1, median, mean, Q3, Max)
```


## Reading Chapter 2-3 of Beaver stats textbook
### Chapter 2: Data with numerical measures
#### Measures of centre
Modal classes are the group of the highest frequency from a continuous variable. The midpoint of which is considered the mode

#### Measures of variability
- Range
- Variance of a sample vs population
- Standard deviation

#### Practical significance of standard deviation
- Tchebysheff's theorem
- Empirical rule

If the range of a data set consists of 4 standard deviation (2 coming out from each side of the mean), then you can say that the range is approximately equal to 4s

$$R = 4s$$$$s = R/4$$
Which should be the same order as the actual calculated standard deviation

#### Measures of relative standing
- Sample z-score: distance between observation and mean, measured in units of standard deviation
- Percentile: 75 percentile is when you are higher than 75% of the sample


### Chapter 3: Describing bivariate data
#### data that has one qualitative component one quantitative
- Bar charts that have different categories as the legend
- Side by side pie charts 

#### Two quantitative variables descriptions
- Scatter plot
  - Identify if there are patterns
  - How strong is the pattern?
  - Are there any unusual observations like outliers or groups?
  
- Correlation coefficient
$$ r = s_{xy} / (s_xs_y) $$
  - Where the numerator is the covariance between x and y
$$ s_{xy} = \frac{\sum{(x_i - \bar{x})(y_i - \bar{y})}}{(n - 1)} $$
or
$$ s_{xy} = \frac{\sum x_iy_i - \frac{(\sum x_i)(\sum y_i)}{n}} {n-1} $$

- The correlation is used to determine the emergence of a pattern in the data set
  - If the pattern forms a negative slope, then r will be negative
  - If the pattern forms a positive slope, then r will be positive
  - If the pattern doesn't have a trend, then r will be close to 0
  
- The best fitting line is the least-squares or regression line
  - the formula for it is as follows:
$$ b = r(\frac{s_{xy}}{(s_x)^2})$$
$$ a = \bar{y} - b\bar{x}$$
$$ y = a + bx $$

## Swirl Lesson 9: Functions in R
Functions are one of the building blocks of R
Functions that start with "Sys" use the values based on your computer's environment

Other common functions include things like **mean()**, **median()**, the remainder operation being %%

Using R means to understand that:
  1. Everything that exists is an object
  2. Everything that happens is a function call
  
You can see the source code for a function if you type out the function name with no parentheses and no arguments

For functions, you are also able to specify a default value of an argument if you don't always want to modify it
  - function(arg1, arg2 = x)
  - R is also able to partially match arguments, where it takes what it thinks is what you mean and uses it, rather than throwing an error
  
Functions can be used as arguments within another function
  - Anonymous functions are when functions are not given a name, but passed through another function or used in some way
  - Eg, **evaluate(function(x){x+1}, 6)**
  
Another common function is the **paste()** function, which combines arguments into one string
  - It takes "..." as the first argument, which means an infinite number
  - A strict rule in R is to have ANY arguments after an ellipsis to have default values

From a list, double brackets allow you to index for specific positions of a value within the list, using the values themselves

## Lab 4: 
### 2. Create the call functions in R
```{r}
f <- function(a){
  return(sum(a, na.rm=T)/length(na.omit(a)))
}
f(c(1,2,3,4))
```

```{r}
d <- function(x, y){
  xs <- mean(y, na.rm = T)
  sdev <- sd(y, na.rm = T)
  return((x - xs) / sdev)
}
d(2, c(1,2,3,4,5,6))

rm(list = ls())
```



# Week 5: Feb 8 - Feb 15
## Module 5: Probability; control statements and loops in R

### Probability
Probability is used as a tool to help evaluate the reliability of our conclusions

Simple events: 

  - Outcome observed on a single repetition of an experiment, which is denoted as $$ E_x $$
  - The set of all simple events is called the sample space $$ S $$
  
$$ S = {E_1, E_2, E_3, E_4, E_5, E_6} $$

If the events occur in such a way that when one happens, the other is impossible, then it is mutually exclusive
  - Probability is another way of saying relative frequency
  
Permutations are used to describe the number of ways to arrange "n" objects, taking "r" objects at a time, where ORDER MATTERS
$$
Permutation("n"objects, take "r") = \frac{n!}{(n-r)!}
$$

Combinations are how many distinct combinations you can make of the "r" objects you take from a group of "n", where order DOES NOT matter
$$
Combination("n" objects, take "r") = \frac{n!}{r!(n-r)!}
$$

$$
Combination("n" objects, take "r") = \frac{Permutation("n" objects, take "r")}{r!}
$$

Another part of probability is the union and intersection of events
$$
P(AuB) = P(A) + P(B) - P(AnB)
$$

Probability of A given B
$$
P(A|B) = \frac{P(AnB)}{P(B)}
$$

### Control statements in R
The control statements in R are if and else
  - The else statement has to be on the same line as the if conditional assessment
```{r}
yippee <- function(a){
  if (a==1){
    print("Wow!") } else {
    print("Aww")
  }}

yippee(1)
```
Another example using else if:

```{r}
f2 <- function(x){
  if (x  == 1){
    print("Hello")
  } else if (x == 0) {
    print("goodbye")
  } else{
    print("confused")
  }
}
f2(4)
```

### Loops in R
Similar to loops in Python, R loops are used to go through multiple indexes at once

For loop
```{r}
for (i in 1:10) {
  print(i)
}
```

The while loop may also be used
```{r}
x <- 1
while (x <= 5) {
  print(x)
  x <- x +1
}
```

Sometimes we need to skip over one iteration
```{r}
for (i in 1:10){
  if (i == 3){
    next
  }
  print(i)
}
```

Or break out of the loop entirely
```{r}
for (i in 1:10){
  if (i == 4){
    break
  }
  print(i)
}
rm(list = ls())
```

## Course reading
### Beaver chapter 4: probability and probability distributions
#### Events and the sample space
- Experiments are the process which an observation is measured
- Simple events are the outcome of a single repetition of the experiment
- An event is a collection of simple events
  - Set of all simple events is a sample space, S
  
  
#### Calculating probabilities using simple events
- Relative frequency = Frequency/n

Requirements for simple event probabilities

  - Each probability must lie between 0 and 1
  - The sum of the probabilities for all simple events in a sample space S must equal 1
  
  
#### Useful counting rules
mn rule: if you have to choose between m things, then n things within, then the total sample space is mn

Permutations are the number of ways we can arrange n distinct objects, taking r at a time

Number of ways to arrange a set of n distinct items is 'n!'

Combinations are the ways we can arrange distinct combinations of n distinct objects, taking r at a time

P(Event) = desired outcome / all outcomes
        = Combination(n=1, r=1) x Combination(n=11, r=3) / Combination(n=12, r=4)
        - This shows the probability of if one person is in the set while others are any body


#### Event relations and probability rules
Union: both A and B, or A or B

Intersection: only A and B

Complement: the event that another event does NOT occur


#### Independence, conditional probability, and the multiplication rule
- Independent events are iff the probability of one does not effect the probability of the other

$$ P(AnB) = P(A)P(B|A) $$
or
$$ P(AnB) = P(B)P(A|B) $$

Conditional probabilities 
$$ P(A|B) = \frac{P(AnB)}{P(B)} if P(B) does not equal 0 $$

For independent events,
$$ P(AnB) = P(A)P(B) $$
$$ P(B|A) = P(B) $$

#### Bayes rule
$$ P(S_i|A) = \frac{P(S_i)P(A|S_i)}{P(S_1)P(A|S_1) + P(S_2)P(A|S_2) + ... + P(S_k)P(A|S_k)} $$
REVIEW BAYES RULE


### Intro stats with R: chapter 3 - Probability distributions

#### 1. Random Sampling
Use the **sample()** function to sample from a data set

#### 2. Probability calculations and combinatorics
Use the **prod()** function to multiply a series of numbers



## Swirl lesson 10: lapply and sapply
- lapply and sapply are known as the loop functions in R
  - They split data into smaller pieces, apply a function to each piece, then combine the results
- to use the *apply functions, you need to specify the object you want to split/apply/combine, as well as the action you would like to perform on the object. For a function, do NOT include the parentheses
  - **lapply** will return a list, hence the 'l' in the front
    - if the output of lapply appear to be the same class, then you can put it into a vector for more compact storing
  - **sapply** will process **lapply** behind the scenes, then simplify as much as it can for you
    - it takes the same parameters as **lapply**
    - if it can't simplify, then it'll return a list

## Lab 5: 
3. Control statements and loops in R
```{r}
marks <- function(x){
  for (i in 1:length(x)) {
    if (x[i] < 60 && x[i] >= 0) {
      print("F")
    } else if (x[i] >= 60 && x[i] < 70) {
      print("D")
    } else if (x[i] >=70 && x[i] < 80) {
      print("C")
    } else if (x[i] >=80 && x[i] < 90) {
      print("B")
    } else if (x[i] >= 90 && x[i] <= 100) {
      print("A")
    } else {
      print("invalid mark")}
  }
}
marks(c(10, 1, -2, 124, 100))
```
# Week 6: Feb 15-Feb 22
## Module 6
### Discrete distributions

1. Uniform probability distributions

  - Each outcome has the same probability
  - Histograms look like a straight, horizontal line
  
2. Bernoulli distributions

  - Two outcomes, denoted by *p* and *1-p*
  - When generalized, turns into the binomial distribution
    - which, when generalized further to represent the probability of event 1 happening, begins to look like a normal distribution
  - Of course, unlike the normal distribution or uniform distribution, the probability of event 1 may not be 5050
  
3. The binomial distribution
$$ 
P(X = k) = C_k^n p^k (1-p)^{n-k} = \frac{n!}{k!(n-k)!} p^k (1-p)^{n-k}
$$

  - Where p = probability of event 1 happening in one instance
    - n = number of trials
    - k = number of successes
  - Mean = np
  - Variance = np(1-p)
  - The probability is always given
  
Eg, You want P(x=3) of a binomial distribution with probability 0.2
```{r}
dbinom(3, 12, 0.2)
# First argument is x, second is n, third is p
# Obtains exact probability of having 3 successes in 12 trials
```

To make a probability that is simply more than a certain number of successes within a set number of trials, you add the probabilities that are above that parameter.

  - Eg, If you want to know the probability of having more than 3 successes in 5 trials, then you add the probabilities of x = 4 and x = 5. 
```{r}
pbinom(3, 5, 0.2)
# first argument is successes, second is n, third is probability
# This function gives you the probability of successes up to 3, so if you want the complement of that, then you should use the inverse, which is 1 - pbinom(3, 5, 0.2)
```

4. Poisson distribution

  - Poisson random variable 'X' is the number of events that occur in a period of time or space during which an average of such events are known
  - The average will always be given as a unit per something, whether that be time, space, or page
    - Denoted by λ
  - Variance = λ
  
$$
P(X = q) = \frac{\lambda^q e^{-\lambda}}{q!}
$$

  - Eg, Average people who come in is 5 per day, find probability of less than two patients
    - Less than 2 means either 1 or 0
      - k = 1 or 0
      - mean = 5
```{r}
dpois(1,5) + dpois(0,5)
ppois(1,5) # This is the cumulative distribution
rm(list = ls())
```
5. Hypergeometric distribution

  - A population has **M** successes in **N** trials
  - We want to find the probability of exactly *k* successes in a sample trial of *n*

$$
P(x=k) = \frac{C_k^M C_{n-k}^{N-M}} {C_n^N}
$$

$$
\mu = n(\frac{M}{N})
$$

$$
\sigma^2 = n(\frac{M}{N})(\frac{N-M}{N})(\frac{N-n}{N-1})
$$

### Basic plotting in R

1. Line charts

```{r}
x <- c(1, 3, 5, 1, 4)
y <- c(2, 5, 1, 4, 3)
plot(x, type = "o", col = "blue")
lines(y, type = "o", pch = 22, lty = 2, col = "red")
```


2. Bar Charts
```{r}
barplot(x, col = "blue")
barplot(y, col = "red")
```

3. Histograms
```{r}
hist(x, col = "blue", main = "distribution of x")
```

4. Pie charts
```{r}
pie(x)
```

5. Dot chart
```{r}
dotchart(x)
rm(list = ls())
```


## Week 6 readings
### beaver chapter 5: discrete distributions
1. The binomial distribution

  - Certain characteristics must appear for the experiment to be considered binomial in nature
    - Each experiment consists of 'n' identical trials
    - each trial results in one of two outcomes
    - probability of a success on a single trial is 'p', while the opposite is (1-p) = 'q'
      - 'p' is consistent
    - trials are independent
    - 'x' denotes the number of successes observed during the 'n' trials
  - As a rule of thumb, if the sample size is larger than 5% of the population, then the resulting experiment is not binomial
  - When 'p' differs, it skews the histogram
    - p = 0.5 will be symmetrical
    - p < 0.5 will be skewed towards the left
    - p > 0.5 will be skewed towards the right
    
2. The poisson probability distribution

  - Can be used as an accurate approximate to the binomial distribution when **'n'** is large and **'np'** is less than 7
  
3. The hypergeometric probability distribution
  
  - Used when the size of the sample is large compared to the population
  - Makes use of population, population portion of successes, sample, desired successes in the sample
  
  
### Intro to stats with R: chapter 3 - probability and distributions section 3.3 and 3.5
Built in distributions in R
 
  - Each has a set of items
    - Density/point probability
    - Cumulated probability
    - Quantiles
    - Pseudo-random numbers

Eg, normal distribution in R
```{r}
x <- seq(-4, 4, 0.1)
plot(x, dnorm(x), type = "l") # plots a chart of the frequency of each value, according to a normal distribution
pnorm(100, mean = 120, sd = 20) # measures the cumulative probability of 100 or less when mean is 120 and sd is 20

# qnorm() can be used to find confidence intervals as well
qnorm(0.025) # gives the 2.5% quantile in the normal distribution, which can serve as one side of a symmetrical 95% confidence interval

xbar <- 83
sigma <- 122
n <- 5
sem <- sigma/sqrt(n)
xbar + sem * qnorm(0.025)
xbar + sem * qnorm(0.975)

rnorm(10) # gives ten random numbers from a normal distribution
  # has parameters mean, sd
  # binomial version rbinom() has parameters size, probability
rm(list = ls())
```

## Lab 6: binomial, poisson, hypergeometric
1. The binomial distribution in R
  
A binomial distribution has been defined by 5 tosses of a fair coin where p = 0.5

a.
```{r}
x <- rbinom(10000, 5, 0.5)
```
b.
```{r}
hist(x)
```
c.
```{r}
y <- rbinom(10, 5, 0.5)
```
d.
```{r}
hist(y)
```
f. 
```{r}
dbinom(1, 5, 0.5) + dbinom(2, 5, 0.5) + dbinom(3, 5, 0.5) + dbinom(4, 5, 0.5) + dbinom(0, 5, 0.5)
```
g. 
```{r}
pbinom(4, 5, 0.5)
```
h. 
```{r}
mean(rbinom(10000, 5, 0.5)) # ??????????????????
```
i.
```{r}
dbinom(10,10,0.2)
# 1.024e-07
```
j.
```{r}
pbinom(4, 12, 0.2)
# 0.9274445
```

2. The poisson distribution
mean = 12 in a 1 minute period

a. 
```{r}
# help("ppois")
```
b. 
```{r}
ppois(1, 12, lower.tail = TRUE)
```
c. 
```{r}
# probability of having 16 or less cars crossing the bridge in any given minute
ppois(16, 12, lower.tail = TRUE)
# since it crosses over the mean, the probability should be more than half
```
d. 
```{r}
# new mean is 12*60 = 720 cars per hour. We want the probability of exactly 0
dpois(0, 720)
rm(list = ls())
```

3. The hypergeometric distribution in R


# Week 7: Midterm exam!

You can't replace a row in a matrix if it is not the right length

Mutually exclusive events

  - When P(AnB) = 0
  
Independent events

  - When P(A) * P(B) = P(AnB)
  
Population of interest:

  - Population in which the researcher wants to draw conclusions from
    - Eg, survey is sent to 1 million, in a sample of 10,000, 6,000 respond with x. The population of interest is the 1 million the survey was sent to
    
Number of simple events is the number of outcomes of a single event, to the power of how many times you are performing the event
  - flipping a coin 4 times gives you a total of 16 simple events
  
  
```{r}
fun <- function(a) {
  while (a < 15){
    a <- a + 1
    print(a)
  }
}

fun(10)
```


# week 8: March 7 - March 14

## Module 8: The normal probability distribution and applications in R

Continuous random variables can assume infinitely many values

The normal curve is a **symmetric** curve which has the shape of a **bell**.

  - The range of a normal distribution has infinite range
  - Tails are approaching but never touching the x-axis
  - The **AREA** under the curve is equal to 1
  
**Equation for a normal curve**

$$
f(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-0.5(\frac{x-\mu}{\sigma})^2}
$$

Which denotes the height of a curve at a given point "x", which is equivalent to the probability of that point "x".

However, since this is a continuous random variable, the probability of a specific point will always be 0. 

In this course, to find the area under the normal distribution, we will use the z score, which is written in terms of standard deviation units. 

In terms of R, we use either p(distribution) or d(distribution)

```{r}
dnorm(2,mean = 0, sd = 1) # deals with height

pnorm(2, mean = 0, sd = 1) # deals with area from the end of the lower tail of the distribution to the value specified

curve(dnorm(x, mean = 0, sd = 1), from = -3, to=3) # function to draw curves, from one value to another
```

Example question, using normal distributions:

- Student A has a mean of 30 minutes to get to school with standard deviation of 3 minutes
- Student B has a mean of 27 minutes to get to school with a standard deviation of 7 minutes

What is height of the probability at x = 28.5 for student A?
```{r}
dnorm(28.6, mean = 30, sd = 3)
```

Plot the distribution period from 15 to 45 minutes of the first student
```{r}
curve(dnorm(x, mean = 30, sd = 3), from = 15, to = 45)
```

Find the probability of the second student arriving 20 minutes or earlier
```{r}
pnorm(20, mean = 27, sd = 7)
```

Find the probability of the first student getting to school between 30 and 35 minutes
```{r}
pnorm(35, mean = 30, sd = 3) - pnorm(30, mean = 30, sd = 3)
rm(list = ls())
```

rnorm() is used to select n random values from a normal distribution, n specifies the number of random selections you want.


# Week 9: Mar 14 - Mar 21
## Module 9: sampling

### Sampling:

**4 Types of Sampling**

- Simple random sampling: in a population, any sample of size n has the same chance of being selected
- Stratified random sampling: first divides population into subpopulation. Then picks from these subpopulations
- Cluster sampling: divides the population into related groups called clusters, then picks from the clusters a random sample
- 1 in k systematic sampling: randomly selects one of the first *k* elements, then every *kth* element thereafter


### Sampling distributions
lower case n is always for sample, while upper case N is for populations

The sampling distribution of a statistic: the probability distribution for the possible values of the statistic that results when random samples of n are repeatedly drawn from the population

Eg, Select two numbers from [5, 10, 15] WITH replacement, so there are 9 total possibilities

  - When you aggregate the means of these pairs, then you will end up with an average of average of 10, which is the same as the mean when you look at the three numbers
  
  
### Central limit theorem
Under general conditions, the sums and means of random samples of measurements drawn from a population tend to have an approximately normal distribution



## Reading chapter 7 beaver stats
- Sampling distribution of the sample mean

If a random sample of n measurements is selected from a population with mean mu and standard deviation sigma, the sampling distribution of the sample mean x bar will have mean mu and standard deviation

$$ 
\frac{\sigma}{\sqrt{n}}
$$

**The standard error** 

The standard error of the estimator because it refers to the precision of the estimator. The standard deviation of the mean is the standard deviation given above.

When sample of n are randomly selected from a finite population N whose mean is mu and variance is sigma squared. Additionally, sample n is not that small compared to population N The standard deviation of x bar is: 

$$ 
\frac{\sigma}{\sqrt{n}} \sqrt{\frac{N-n}{N-1}}
$$

If the population N is **large** relative to the sample size, then standard deviation of x bar is the same as the one before.



## Lab 8: sampling

### 1. Sampling distribution

1. Given a vector of three numbers x = c(5, 10, 15), use the permutation() function to generate all possible outcomes for two selected numbers.

```{r}
library(gtools)
x <- c(5, 10 ,15)
perm <- permutations(length(x), 2, x, repeats.allowed = TRUE)
perm
```

2. Use the row means() function to calculate the average of each possible pair in the previous step
```{r}
mean_perm <- rowMeans(perm)
mean_perm
```

### 2. Discrete distributions convergence

when the sample set is large, poisson distribution with lambda "n" converges to normal distribution with mean "n" and variance "n"

Binomial distribution will converge to a normal distribution with mean "np" and variance "np(1-p)"



# Week 10: Mar 22 to Mar 29
## Module 10: Linear regression and linear models in R

Linear regression is an approach for modelling the relationship between a dependent variable and one or more independent variables. The case of more than one independent variable is called multiple linear regression.

Rather than y = mx + b, in stats we use y = alpha + beta*x. It will still find the value of y when x is given to us.

### Finding the line of best fit

Least square method:

With data points plotted on a graph, a line is considered the best fit if the cumulative **SQUARED** deviation from each datapoint is the lowest it can be.

Method to obtain line of best fit. **y = mx + b**

  - Start with a set of x and y values ([x1, x2, x3], [y1, y2, y3])
  - Calculate mean of both x and y values
  - Calculate coefficient of line: m
  
$$
S_{xy} = \sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y}) = (computing formula)\sum x_i y_i - \frac{(\sum x_i)(\sum y_i)}{n}
$$

$$
s_{xx} = \sum (x_i - \bar{x})^2 = (computing formula)\sum_{i=1}^{n}x_i^2 - (\sum_{i=1}^{n}x_i^2)/n
$$

$$
m = \frac{s_{xy}}{s_{xx}}
$$

  - Calculate b, the y intercept
  
  The value of b is when you set y = mean of y and x = mean of x
  b = y - mx
  
  
### Linear regression in R

First, find any missing values in the dataset you are working with using the sum and which functions

  sum(is.na(dataset$column)) -> gives number of na values within the column
  which(is.na(dataset$column)) -> gives where the na value is in the column

Then, remove or replace the NA value(s) using na.omit and assigning to a new variable

  new_dataset <- na.omit(dataset)

Now, use the lm() function to perform linear regression on the columns you choose

  lm(column1(y) ~ column2(x), data = new_dataset)
  
This function will give the coefficient and intercept, so you can then determine an expected y value given any x value

## Intro to stats with R: chapter 6 - Regression and correlation

### 6.1 simple linear regression

```{r}
library(ISwR)
attach(thuesen)
```

```{r}
summary(lm(short.velocity ~ blood.glucose)) # shows more information about the linear model created

# First, a dissection of what you called
# Then, distribution of the residuals, where the median should not be far from 0
# After, we see the intercept and regression coefficient, where the stars show how significant
  # *** means p value is between 0 and 0.001, while * means p value is between 0.01 to 0.05. Though these typically won't affect your work
# Next, residual standard error: variation of the observations around the regression line. It will also tell you if there are missing values
# An R squared value is given to show how well the line fits with the data. Closer to 1 is better, closer to NEGATIVE 1 is bad fit
# Finally, an F test is given for the hypothesis that the regression coefficient is 0
```

### 6.2 residuals and fitted values

The fitted() function gives the y values you would EXPECT given a x value from the dataset. This is what the value would be if on the line of best fit.

The resid() function shows the difference between the fitted values and the observed values.

To instantly get rid of any NA values that may be present when you're plotting out a data set, then the na.exclude() call can do that for you. I would prefer to use it as an option, but you can use it as an argument in lm() as well

```{r}
lm.velo <- lm(short.velocity ~ blood.glucose)
lm.velo
```

To create a plot that has a line of best fit AND the residuals going towards the line of best fit, use the segments() function to draw line segments. The arguments to pass will be endpoint coordinates in the order **(x1, y1, x2, y2, ..., xn, yn)**

```{r}
segments(blood.glucose, fitted(lm.velo), blood.glucose, short.velocity)
```


### 6.3 prediction and confidence bands

Fitted lines have two uncertainty bands around them

  - Confidence bands - the narrow type - reflect uncertainty about the line itself. They will be narrowest at the mean, and then will diverge from there
  - Prediction bands - the wide type - reflect uncertainty about the future observations. They will capture most of the known observations to allow for more leeway for future observations. They approach the true line plus minus 2 standard deviations, which when set on a normal distribution with more observations, will include 95% of the observations. These limits are limited in that they rely on normally distributed errors and a constant variance, so they are not good for small samples in particular.
    - Can be pulled using the predict() function, with the linear model as an argument
    - Additionally, arguments can be specifying if you want the new observations to be within the confidence bands or prediction bands
      - predict(lm.velo, int="c"), predict(lm.velo, int="p")
      
It is possible to add prediction and confidence intervals to a scatterplot using matlines(), but there are a few caveats to take note of.

  - sometimes column values are in random order
  - prediction limits extendd outside plot region
  - matlines() command needs to be prevented from cycling through line styles and colours
  
The solution is to *predict in a new data frame* containing suitable x values
```{r}
pred.frame <- data.frame(blood.glucose=4:20)
pp <- predict(lm.velo, int = "p", newdata=pred.frame)
pc <- predict(lm.velo, int = "c", newdata=pred.frame)
plot(blood.glucose, short.velocity, ylim = range(short.velocity, pp, na.rm=T))
pred.gluc <- pred.frame$blood.glucose
matlines(pred.gluc, pc, lty=c(1,2,3), col = "black")
matlines(pred.gluc, pp, lty=c(1,2,3), col = "black")
```


### 6.4 Correlation

#### 6.4.1 Pearson correlation
$$
r = \frac{\sum (x_i - \bar{x}) (y_i - \bar{y})} {\sqrt {\sum (x_i - \bar{x})^2 \sum (y_i - \bar{y})^2}}
$$
where **r** is the empirical correlation coefficient. **|r|** will be less than 1 if there is a non-perfect linear relation between $$x_i$$ and $$y_i$$

We can use the function cor() to compute the correlation between two or more vectors. You will need to pass a few extra arguments to avoid problems:

  - use = "complete.obs" allows you to only use complete parts of the vectors
  
```{r}
cor(blood.glucose, short.velocity, use = "complete.obs")
# 0.4167546
```
